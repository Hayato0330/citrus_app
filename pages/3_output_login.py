# output_login.py
import streamlit as st
import numpy as np
import pandas as pd
from urllib.parse import quote


# ===== ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•° =====
def load_data(csv_path: str) -> pd.DataFrame | None:
    """ç‰¹å¾´é‡CSVã‚’èª­ã¿è¾¼ã‚€ã€‚å¤±æ•—ã—ãŸã‚‰ None ã‚’è¿”ã™ã€‚"""
    try:
        return pd.read_csv(csv_path)
    except Exception as e:
        st.error(f"CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None


def score_items(df: pd.DataFrame, user_vec: np.ndarray,
                season_pref: str = "", season_boost: float = 0.03) -> pd.DataFrame:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«ã¨ç‰¹å¾´é‡ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰"""
    feature_cols = ["brix", "acid", "bitter", "smell", "moisture", "elastic"]

    if not all(col in df.columns for col in feature_cols):
        st.error("CSVã«å¿…è¦ãªç‰¹å¾´é‡ã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        st.stop()

    X = df[feature_cols].astype(float).values

    def normalize(v):
        return v / (np.linalg.norm(v) + 1e-8)

    user_vec = normalize(user_vec)
    X_norm = np.array([normalize(x) for x in X])

    scores = X_norm @ user_vec

    # å­£ç¯€ä¸€è‡´ã«åŠ ç‚¹
    if season_pref and "season" in df.columns:
        mask = df["season"].astype(str).str.contains(season_pref)
        scores = scores + mask.astype(float) * season_boost

    df = df.copy()
    df["score"] = scores
    return df.sort_values("score", ascending=False).reset_index(drop=True)


# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° =====
def build_amazon_url(name: str) -> str:
    query = quote(f"{name} ç”Ÿæœ ãƒ•ãƒ«ãƒ¼ãƒ„ -è‹— -è‹—æœ¨ -ã®ã¼ã‚Š -ã‚¸ãƒ¥ãƒ¼ã‚¹ -ã‚¼ãƒªãƒ¼ -ç¼¶ -æœ¬")
    return f"https://www.amazon.co.jp/s?k={query}&i=grocery"

def build_rakuten_url(name: str) -> str:
    return f"https://search.rakuten.co.jp/search/mall/{quote(name)}/"

def build_satofuru_url(name: str) -> str:
    return f"https://www.satofull.jp/search/?q={quote(name)}"

def build_twitter_share(names: list[str]) -> str:
    # é †ä½ä»˜ã + æ”¹è¡Œ
    ranked_text = "\n".join([f"{i+1}ä½ {name}" for i, name in enumerate(names)])
    text = quote(f"ãŠã™ã™ã‚ã®æŸ‘æ©˜ ğŸŠ\n{ranked_text}\n#æŸ‘æ©˜ãŠã™ã™ã‚")

    share_url = st.secrets.get("public_app_url", "")
    url_query = f"&url={quote(share_url)}" if share_url else ""

    return f"https://twitter.com/intent/tweet?text={text}{url_query}"



# ===== ãƒšãƒ¼ã‚¸è¨­å®š =====
st.set_page_config(page_title="æŸ‘æ©˜ãŠã™ã™ã‚è¨ºæ–­ - çµæœ", page_icon="ğŸŠ", layout="wide")

# èƒŒæ™¯è‰²ï¼ˆè–„ã„ã‚ªãƒ¬ãƒ³ã‚¸ï¼‰
st.markdown(
    """
    <style>
    .stApp {
        background-color: #FFF8F0;
    }
    </style>
    """,
    unsafe_allow_html=True
)


# ===== ãƒ‡ãƒ¼ã‚¿å–å¾— =====
ranked = st.session_state.get("ranked_results", None)
topk = 3

if ranked is None:
    df = load_data("citrus_features.csv")

    if df is None:
        # --- ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ ---
        df = pd.DataFrame({
            "Item_name": ["æ¸©å·ã¿ã‹ã‚“", "ãƒãƒ³ã‚«ãƒ³", "ã¯ã£ã•ã"],
            "brix": [5, 4, 3],
            "acid": [2, 3, 4],
            "bitter": [1, 2, 3],
            "smell": [3, 4, 2],
            "moisture": [5, 4, 3],
            "elastic": [2, 3, 4],
            "season": ["å†¬", "å†¬ã€œæ˜¥", "æ˜¥"],
            "description": ["ç”˜ãã¦é£Ÿã¹ã‚„ã™ã„å®šç•ªã¿ã‹ã‚“", "é¦™ã‚Šè±Šã‹ã§äººæ°—ã®æŸ‘æ©˜", "ã•ã£ã±ã‚Šã¨ã—ãŸå‘³ã‚ã„"],
            "image_path": [
                "https://via.placeholder.com/200x150?text=Mikan",
                "https://via.placeholder.com/200x150?text=Ponkan",
                "https://via.placeholder.com/200x150?text=Hassaku",
            ]
        })

    # ãƒ€ãƒŸãƒ¼å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«
    user_vec = np.array([2, 3, 2, 3, 4, 5], dtype=float)
    season_pref = ""

    ranked = score_items(df, user_vec, season_pref=season_pref, season_boost=0.03)
    st.session_state.ranked_results = ranked


# ===== UI =====
st.markdown("### ğŸŠ æŸ‘æ©˜ãŠã™ã™ã‚è¨ºæ–­ - çµæœ")

top_items = ranked.head(topk)

# å››è±¡é™ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
cols_top = st.columns(2)
cols_bottom = st.columns(2)
quadrants = [cols_top[0], cols_top[1], cols_bottom[0], cols_bottom[1]]

for idx, row in enumerate(top_items.itertuples(), start=1):
    with quadrants[idx - 1]:
        st.markdown(f"#### {idx}. {row.name}")

        image_url = getattr(row, "image_path", None) or "https://via.placeholder.com/200x150?text=No+Image"
        st.image(image_url, use_container_width=True)

        match_percent = f"{row.score*100:.1f}%"
        st.markdown(
            f"**ãƒãƒƒãƒåº¦:** <span style='color:#f59e0b;'>{match_percent}</span>",
            unsafe_allow_html=True
        )

        # st.caption(f"å­£ç¯€: {getattr(row, 'season', '-')}")
        st.caption(getattr(row, "description", ""))

        # å¤–éƒ¨ãƒªãƒ³ã‚¯
        st.markdown(f"[Amazonã§è¦‹ã‚‹]({build_amazon_url(row.name)})", unsafe_allow_html=True)
        st.markdown(f"[æ¥½å¤©ã§è¦‹ã‚‹]({build_rakuten_url(row.name)})", unsafe_allow_html=True)
        st.markdown(f"[ã•ã¨ãµã‚‹ã§è¦‹ã‚‹]({build_satofuru_url(row.name)})", unsafe_allow_html=True)


# === å³ä¸‹ã€Œã¾ã¨ã‚ã€ãƒ–ãƒ­ãƒƒã‚¯ ===
with quadrants[3]:
    st.markdown("#### ã¾ã¨ã‚")
    citrus_names = [r.name for r in top_items.itertuples()]
    twitter_url = build_twitter_share(citrus_names)
    st.markdown(f"[Xã§ã‚·ã‚§ã‚¢ã™ã‚‹]({twitter_url})", unsafe_allow_html=True)

st.caption("â€» ãƒãƒƒãƒåº¦ã¯å—œå¥½ã¨ã®è¿‘ã•ã‚’ % è¡¨è¨˜ã€‚å­£ç¯€ä¸€è‡´ãŒã‚ã‚‹å ´åˆã¯åŠ ç‚¹ã•ã‚Œã¾ã™ã€‚")
